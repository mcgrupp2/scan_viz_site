---
title: "Model Testing Results"
output:
  html_document:
    css: "site_themes.css"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=F,message=F)
library(knitr)
```


## {.tabset}


```{css, echo=FALSE}

.chart-wrapper {
  position: absolute;
  left: 50px;
}

.vega-bind:first-child {
  position: fixed;
  left: 20px;
  top: 300px;
}

.vega-bind:nth-child(2) {
  position: fixed;
  left: 20px;
  top: 400px;
}

.vega-bind:last-child {
    position: absolute;
    left: 700px;
    top: -60px;
}

```


```{r message=FALSE, warning=FALSE, include=FALSE}
library(reticulate)
library(vegawidget)
library(bsplus)
library(htmltools)
```




```{python include=FALSE}
import numpy as np
import pandas as pd
import altair as alt
from sklearn.metrics import balanced_accuracy_score, log_loss, f1_score, precision_score, accuracy_score,recall_score,roc_curve,precision_recall_curve,matthews_corrcoef,cohen_kappa_score,auc,confusion_matrix

alt.data_transformers.disable_max_rows()

```

```{python include=FALSE}
source = pd.read_csv('/Users/jason/Library/CloudStorage/OneDrive-UW/Documents/research_projects/202109_dedx/220202_preds.csv')

source=source.iloc[:,1:]
source['result']=source['target'].map({0:"Neg",1:"Pos"})
y_scoring2=source['target']
rf_y_pred2=source['rf']
xg_y_pred2=source['xg']
logit_y_pred2=source['logit']
et_y_pred2=source['et']
gbc_y_pred2=source['gbc']
eclf_y_pred2=source['eclf']

rf_fpr, rf_tpr, rf_thresholdz = roc_curve(y_scoring2,rf_y_pred2)
xg_fpr, xg_tpr, xg_thresholdz = roc_curve(y_scoring2,xg_y_pred2)
logit_fpr, logit_tpr, logit_thresholdz = roc_curve(y_scoring2,logit_y_pred2)
et_fpr, et_tpr, et_thresholdz = roc_curve(y_scoring2,et_y_pred2)
gbc_fpr, gbc_tpr, gbc_thresholdz = roc_curve(y_scoring2,gbc_y_pred2)
eclf_fpr, eclf_tpr, eclf_thresholdz = roc_curve(y_scoring2,eclf_y_pred2)



rf_precision, rf_recall, rf_thresholds = precision_recall_curve(y_scoring2, rf_y_pred2) 
xg_precision, xg_recall, xg_thresholds = precision_recall_curve(y_scoring2, xg_y_pred2) 
logit_precision, logit_recall, logit_thresholds = precision_recall_curve(y_scoring2, logit_y_pred2)

et_precision, et_recall, et_thresholds = precision_recall_curve(y_scoring2, et_y_pred2)
gbc_precision,gbc_recall, gbc_thresholds = precision_recall_curve(y_scoring2, gbc_y_pred2)

eclf_precision, eclf_recall, eclf_thresholds = precision_recall_curve(y_scoring2, eclf_y_pred2) 

def compute_f1(prec,recall):
    return (2 * prec * recall) / (prec + recall)

rf_best_thresh=rf_thresholds[np.nanargmax([compute_f1(p,r) for p,r in zip(rf_precision,rf_recall)])]
xg_best_thresh=xg_thresholds[np.nanargmax([compute_f1(p,r) for p,r in zip(xg_precision,xg_recall)])]
logit_best_thresh=logit_thresholds[np.nanargmax([compute_f1(p,r) for p,r in zip(logit_precision,logit_recall)])]
et_best_thresh=et_thresholds[np.nanargmax([compute_f1(p,r) for p,r in zip(et_precision,et_recall)])]
gbc_best_thresh=gbc_thresholds[np.nanargmax([compute_f1(p,r) for p,r in zip(gbc_precision,gbc_recall)])]
eclf_best_thresh=eclf_thresholds[np.nanargmax([compute_f1(p,r) for p,r in zip(eclf_precision,eclf_recall)])]

rf_gmeans = np.sqrt(rf_tpr * (1-rf_fpr))
xg_gmeans = np.sqrt(xg_tpr * (1-xg_fpr))
logit_gmeans = np.sqrt(logit_tpr * (1-logit_fpr))
et_gmeans = np.sqrt(et_tpr * (1-et_fpr))
gbc_gmeans = np.sqrt(gbc_tpr * (1-gbc_fpr))
eclf_gmeans = np.sqrt(eclf_tpr * (1-eclf_fpr))
#sclf_gmeans = np.sqrt(sclf_tpr * (1-sclf_fpr))
# locate the index of the largest g-mean
rf_ix = np.argmax(rf_gmeans)
xg_ix = np.argmax(xg_gmeans)
logit_ix = np.argmax(logit_gmeans)
et_ix = np.argmax(et_gmeans)
gbc_ix = np.argmax(gbc_gmeans)
eclf_ix = np.argmax(eclf_gmeans)

# # apply threshold to positive probabilities to create labels
def to_labels(pos_probs, threshold):
 	return (pos_probs >= threshold).astype('int')

```




```{python include=FALSE,warning=F,message=F}
alt.data_transformers.disable_max_rows()

source_df=source.reset_index().melt(id_vars=['index','target',"result"],var_name='classifier',value_name='pred')


# sns.scatterplot(data=df, x="index", y="pred_prob",hue='response')
# plt.show()
y_slider_df=pd.DataFrame({'thresh': np.arange(0,1,0.0001)})

hi_slider = alt.binding_range(name="High Threshold", min=0, max=1, step=0.001)
hi_select_thresh = alt.selection_single(fields=['thresh'],
                                   bind=hi_slider, init={'thresh': round(eclf_best_thresh,3)})

lo_slider = alt.binding_range(min=0, max=1, step=0.001,name="Low Threshold")
lo_select_thresh = alt.selection_single(fields=['thresh'],
                                   bind=lo_slider, init={'thresh': round(eclf_thresholds[eclf_ix],3)})

hi_thresh_line = alt.Chart(y_slider_df).mark_rule(color="lightgray").encode(y='thresh:Q',opacity=alt.value(0.05)).add_selection(
    hi_select_thresh
).transform_filter(
    hi_select_thresh
)

lo_thresh_line = alt.Chart(y_slider_df).mark_rule(color="lightgray").encode(y='thresh:Q',opacity=alt.value(0.05)).add_selection(
    lo_select_thresh
).transform_filter(
    lo_select_thresh
)


genre_dropdown = alt.binding_select(options=np.unique(source_df['classifier']),name="Choose Model:\n ",labels=['Ensemble',"Extra Trees","Gradient Boost","Logistic Regression", "Random Forest", "XGBoost"])
genre_select = alt.selection_single(fields=['classifier'], bind=genre_dropdown,init={'classifier': 'et'})


colorz = alt.condition(alt.datum.pred<=hi_select_thresh.thresh,
                      alt.value('orangered'),
                      alt.Color('target:Q', scale=alt.Scale(scheme='greens')),legend=None)


opacityz = alt.condition(alt.datum.target==0, alt.value(0.2), alt.value(0.8),legend=None)

def first_base():
     return alt.Chart(source_df).add_selection(
         genre_select
     ).transform_filter(
         genre_select
     ).transform_filter(
         (alt.datum.pred <= lo_select_thresh.thresh) 
     )

def base_plot(filter_criteria):
     return alt.Chart(source_df).transform_filter(
         genre_select
     ).transform_filter(
         (filter_criteria) 
     )

def row_calcs(base):
    # base=base_plot(filter_criteria)
    return base.transform_aggregate(
        total_count2='count(target)',
        total_pos='sum(target)',
    ).transform_calculate(
        tru_negs=(alt.datum.total_count2-alt.datum.total_pos),
        pop_pct=(alt.datum.total_count2/source.shape[0]),
        tpos_pct=(alt.datum.total_pos/source[source['target']==1].shape[0]),
        spos_pct=(alt.datum.total_pos/alt.datum.total_count2),
        npv=(alt.datum.tru_negs/alt.datum.total_count2)
    )

def bar_plot(base,colore,fieldz,toolz,titlez):
    return row_calcs(base).mark_bar(color=colore).encode(
    y=alt.Y(fieldz,scale=alt.Scale(domain=(0, 1)),title=titlez),
    tooltip=toolz
    ).properties(width=40).interactive()

def label_plot(base,fieldz):
    return row_calcs(base).mark_text(dy=-5, color='black').encode(
    y=alt.Y(fieldz, stack='zero'),
    text=alt.Text(fieldz, format='.3p')
    )

def cat_lbdBar_plot(base,colore,fieldz,toolz,titlez):
    return (bar_plot(base,colore,fieldz,toolz,titlez)+label_plot(base,fieldz))


lbd_bar_bases={
'pop':{
    'titlez':"Percent of Total Population Served",
    'fieldz':'pop_pct:Q',
    'toolz':[
        alt.Tooltip('pop_pct:Q',format='.3p',title="Percentage"),
        alt.Tooltip('total_count2:Q',title="Total Count"),
        alt.Tooltip('tru_negs:Q',title="Negatives"),
        alt.Tooltip('total_pos:Q',title="Positives")]
        },
'tpos':{
    'titlez':"Percent of Total Positives",
    'fieldz':'tpos_pct:Q',
    'toolz':[
        alt.Tooltip('tpos_pct:Q',format='.3p',title="Percentage"),
        alt.Tooltip('total_count2:Q',title="Total Count"),
        alt.Tooltip('total_pos:Q',title="Positives"),]
        },
'npv':{
    'titlez':"Negative Predictive Value",
    'fieldz':'npv:Q',
    'toolz':[
        alt.Tooltip('npv:Q',format='.3p',title="Negative Predictive Value"),
        alt.Tooltip('total_count2:Q',title="Total Count"),
        alt.Tooltip('tru_negs:Q',title="True Negatives"),
        alt.Tooltip('total_pos:Q',title="False Negatives (Pos)")],
        },
'spos':{
    'titlez':"Percentage of Positives in Ranges",
    'fieldz':'spos_pct:Q',
    'toolz':[
        alt.Tooltip('spos_pct:Q',format='.3p',title="Percentage"),
        alt.Tooltip('total_count2:Q',title="Total Count"),
        alt.Tooltip('tru_negs:Q',title="Negatives"),
        alt.Tooltip('total_pos:Q',title="Positives")]
    }
}

row_bases={
    'firstRow':{
        'base':base_plot(alt.datum.pred <= lo_select_thresh.thresh),
        'colore':'lightgray'},
    'secondRow':{
        'base':base_plot((alt.datum.pred > lo_select_thresh.thresh) & (alt.datum.pred <= hi_select_thresh.thresh)),
        'colore':'orangeRed'},
    'thirdRow':{
        'base':base_plot((alt.datum.pred > hi_select_thresh.thresh)),
        'colore':'seagreen'},
}

def lbd_bar_plot(lbd_bar_base,row_base):
    call_dict=lbd_bar_bases[lbd_bar_base].copy()
    call_dict.update(row_bases[row_base])
    return cat_lbdBar_plot(**call_dict)

dotplot_tools=[alt.Tooltip('pred',title="Probability",format='.3p'), alt.Tooltip('result',title="Test Result")]

fR_dot=first_base().mark_circle(size=60,color='lightgrey').encode(
    x=alt.X('index',axis=None,scale=alt.Scale(domain=(0, source.shape[0]))),
    y=alt.Y('pred',scale=alt.Scale(domain=(0, 1)),axis=alt.Axis(title="Predicted Probability")),
    tooltip=dotplot_tools
).properties(title="Model Diagnosed",width=500).interactive()

# pop,tpos,npv,spos
fR_poplbdBar=lbd_bar_plot('pop','firstRow')
fR_tposlbdBar=lbd_bar_plot('tpos','firstRow')
fR_npvlbdBar=lbd_bar_plot('npv','firstRow')


firstRow=(fR_dot+lo_thresh_line|(fR_poplbdBar|fR_tposlbdBar|fR_npvlbdBar))

#%%

def dot_plot(base,titlez,arg_dicts):
    return base.mark_circle(size=60).encode(**arg_dicts).properties(title=titlez,width=500).interactive()

dot_plot_args={'x':alt.X('index',axis=None,scale=alt.Scale(domain=(0, source.shape[0]))),
    'y':alt.Y('pred',scale=alt.Scale(domain=(0, 1)),axis=alt.Axis(title="Predicted Probability")),
    'tooltip':dotplot_tools}
    # 'opacity':dopacity,}

sR_dot_dict=dot_plot_args.copy()
sR_dot_dict.update({'color':colorz,'opacity':opacityz})

sR_dot=dot_plot(row_bases['secondRow']['base'],"Higher Performance Tests",sR_dot_dict)

sR_poplbdBar=lbd_bar_plot('pop','secondRow')
sR_tposlbdBar=lbd_bar_plot('tpos','secondRow')
sR_sposlbdBar=lbd_bar_plot('spos','secondRow')

secondRow=((sR_dot+hi_thresh_line+lo_thresh_line)|sR_poplbdBar|sR_tposlbdBar|sR_sposlbdBar)

tR_dot_dict=dot_plot_args.copy()
tR_dot_dict.update({'color':(alt.Color('target:Q',legend=None))})

tR_dot=dot_plot(row_bases['thirdRow']['base'],"Rapid Diagnostic Tests",tR_dot_dict)

tR_poplbdBar=lbd_bar_plot('pop','thirdRow')
tR_tposlbdBar=lbd_bar_plot('tpos','thirdRow')
tR_sposlbdBar=lbd_bar_plot('spos','thirdRow')

thirdRow=((tR_dot+hi_thresh_line)|tR_poplbdBar|tR_tposlbdBar|tR_sposlbdBar)

# (firstRow)&(secondRow)&(thirdRow)
```


### Dashboard

```{r echo=FALSE}
bs_modal(
  id = "modal_markdown", 
  title = "Visualization Explanation",
  body = includeMarkdown("stuff.md"),
  size = "large"
)
bs_button("Visualization Info", button_type = "success",button_size ="extra-small",id="info_modal") %>%
  bs_attach_modal("modal_markdown")
```

```{python echo=F,message=FALSE,warning=FALSE}
# ind_chart=(firstRow_dot+yrule2|((bar+firstRow_barlabel)|(bar2+text2)|barb+textb))&(base2+yrule+yrule2|((bar3+text3)|(bar4+text4)|(barc+textc)))&(base3+yrule|((bar5+text5)|(bar6+text6)|(bard+textd)))

# ichart=ind_chart.to_json() 
# ind_chart
(firstRow)&(secondRow)&(thirdRow)
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# as_vegaspec(py$ichart)
```


```{r echo=F}
htmltools::includeScript(path = "helpers.js")
```


### Plots


```{python echo=F,message=FALSE,warning=FALSE}

# tn, fp, fn, tp

# confusion_matrix(y_scoring2,to_labels(rf_y_pred2,0.001)).ravel()

def calc_at_thresh(preds,thresh,classifier):
    # return np.hstack((classifier,confusion_matrix(y_scoring2,to_labels(preds,thresh)).ravel()))
    return confusion_matrix(y_scoring2,to_labels(preds,thresh)).ravel()

# [x/1000 for x in range(1,1001)]


cms=[calc_at_thresh(source['rf'],y,'rf') for y in [x/1000 for x in range(0,1001)]]

cmf=[np.hstack((y,x)).tolist() for x,y in zip(cms,[x/1000 for x in range(0,1001)])]

# cm_df=pd.DataFrame(cmf,columns=['thresh','classifier','tn','fp','fn','tp'])

# cm_df[['tn','fp','fn','tp']]=cm_df[['tn','fp','fn','tp']].astype(float)

cm_df=pd.DataFrame(cmf,columns=['thresh','tn','fp','fn','tp'])
#%%
alt.data_transformers.disable_max_rows()

# source_df=source.reset_index().melt(id_vars=['index','target',"result"],var_name='classifier',value_name='pred')
slider = alt.binding_range(name="Threshold", min=0, max=1, step=0.001)
select_thresh = alt.selection_single(fields=['thresh'],
                                   bind=slider, init={'thresh': round(eclf_best_thresh,3)})

# genre_dropdown = alt.binding_select(options=np.unique(cm_df['classifier']),name="Choose Model:\n ",labels=["Random Forest"])
# genre_select = alt.selection_single(fields=['classifier'], bind=genre_dropdown,init={'classifier': 'rf'})


tn=alt.Chart(cm_df.loc[:, cm_df.columns != 'classifier']).add_selection(
     select_thresh
    ).transform_filter(
        select_thresh
    ).mark_text().encode(
    text=alt.Text('tn:Q'),
    color=alt.Color('tn:Q', scale=alt.Scale(scheme='redyellowgreen'),legend=None)
).properties(width=40,title='TN')


fp=alt.Chart(cm_df).transform_filter(
        select_thresh
    ).mark_text().encode(
    text=alt.Text('fp:Q'),
    color=alt.Color('fp:Q', scale=alt.Scale(scheme='redyellowgreen'),legend=None)
).properties(width=40,title='FP')


fn=alt.Chart(cm_df).add_selection(
     select_thresh
    ).transform_filter(
        select_thresh
    ).mark_text().encode(
    text=alt.Text('fn:Q'),
    color=alt.Color('fn:Q', scale=alt.Scale(scheme='redyellowgreen'),legend=None)
).properties(width=40,title='FN')


tp=alt.Chart(cm_df).add_selection(
     select_thresh
    ).transform_filter(
        select_thresh
    ).mark_text().encode(
    text=alt.Text('tp:Q'),
    color=alt.Color('tp:Q', scale=alt.Scale(scheme='redyellowgreen'),legend=None)
).properties(width=40,title='TP')


ichart=((tn|fp)&(fn|tp)).configure_title(fontSize=12).configure(background='#3b3e46').to_json() 
# f

# ichart=((tn|fp)&(fn|tp)).configure_title(fontSize=12).configure(background='#D9E9F0').to_json() 

# ichart=ind_chart.to_json() 
# ind_chart
# (firstRow)&(secondRow)&(thirdRow)
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
as_vegaspec(py$ichart)
```

### Tables

We show the data in this tab.

```{r}

```
